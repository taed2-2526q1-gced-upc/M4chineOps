# -*- coding: utf-8 -*-
"""model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u1jsGrgy1SSmMVwCsutE8fb5p9YywiVd
"""

# 0) Setup & imports

!pip install tensorflow==2.15.0 opencv-python scikit-learn pandas tqdm --quiet

import os, math, cv2, glob, json
import numpy as np
import pandas as pd
from tqdm import tqdm

import tensorflow as tf
from tensorflow.keras.applications import Xception
from tensorflow.keras.applications.xception import preprocess_input
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.models import Model

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix

# Reprodueix de forma determinista (fins on es pugui)
np.random.seed(42)
tf.random.set_seed(42)

print("TensorFlow:", tf.__version__)
print("GPU available:", len(tf.config.list_physical_devices('GPU')) > 0)

# 1) Config

VIDEO_ROOT = "videos"      # arrel dels splits
SPLITS = ["train", "test"] # canvia si vols "valid"
CLASSES = ["real", "fake"] # maparem real->1, fake->0 (pots invertir si vols)
FRAMES_PER_VIDEO = 10      # quants frames extreus per vídeo
AGGREGATION = "mean"       # "mean" o "sum"
IMG_SIZE = (299, 299)      # Xception
BATCH_SIZE = 32
CSV_OUT = "video_embeddings.csv"  # on guardarem el DataFrame

label_map = {"real": 1, "fake": 0}


# 2) Model Xception per embeddings

base = Xception(weights="imagenet", include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
emb_model = Model(inputs=base.input, outputs=GlobalAveragePooling2D()(base.output))  # -> vector 2048
emb_dim = emb_model.output_shape[-1]
print("Embedding dim:", emb_dim)  # 2048


# 3) Utils: extreure frames i embeddar

def sample_frame_indices(num_frames, k):

    idxs = sample_frame_indices(total, k=10)  # dins read_video_frames_uniform

    if num_frames <= 0:
        return []
    # indices uniformes
    return [int(round(i * (num_frames - 1) / max(1, k - 1))) for i in range(k)] if k > 1 else [0]

def read_video_frames_uniform(path, k=10):

    cap = cv2.VideoCapture(path)
    if not cap.isOpened():
        return []
    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    idxs = sample_frame_indices(total, k)
    frames = []
    for target in idxs:
        cap.set(cv2.CAP_PROP_POS_FRAMES, target)
        ok, frame = cap.read()
        if not ok or frame is None:
            continue
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frames.append(frame)
    cap.release()
    return frames

def preprocess_frames(frames, img_size=(299, 299)):
    """
    Resize -> float -> preprocess_input (Xception).
    """
    arr = []
    for f in frames:
        f = cv2.resize(f, img_size, interpolation=cv2.INTER_AREA)
        arr.append(f.astype(np.float32))
    x = np.stack(arr, axis=0)            # [N, H, W, 3]
    x = preprocess_input(x)              # Xception preprocess
    return x

def embed_frames(frames_np):
    """
    Calcula embeddings [N, 2048] amb el model Keras en batchs.
    """
    embs = []
    for i in range(0, frames_np.shape[0], BATCH_SIZE):
        batch = frames_np[i:i+BATCH_SIZE]
        e = emb_model.predict(batch, verbose=0)
        embs.append(e)
    return np.vstack(embs)  # [N, 2048]

def aggregate_video_embeddings(frame_embs, how="mean"):
    if frame_embs.size == 0:
        return None
    if how == "sum":
        return frame_embs.sum(axis=0)
    # default mean
    return frame_embs.mean(axis=0)


# 4) Recorre els vídeos, calcula embeddings per vídeo i munta DataFrame

rows = []
for split in SPLITS:
    for cls in CLASSES:
        folder = os.path.join(VIDEO_ROOT, split, cls)
        if not os.path.isdir(folder):
            print(f"[WARN] No existeix: {folder}")
            continue
        videos = sorted(glob.glob(os.path.join(folder, "*.mp4")) +
                        glob.glob(os.path.join(folder, "*.mov")) +
                        glob.glob(os.path.join(folder, "*.avi")) +
                        glob.glob(os.path.join(folder, "*.mkv")))
        print(f"{split}/{cls}: {len(videos)} vídeos")
        for vp in tqdm(videos, desc=f"{split}/{cls}"):
            frames = read_video_frames_uniform(vp, k=FRAMES_PER_VIDEO)
            if len(frames) == 0:
                continue
            x = preprocess_frames(frames, IMG_SIZE)
            frame_embs = embed_frames(x)            # [k, 2048]
            vid_emb = aggregate_video_embeddings(frame_embs, AGGREGATION)  # [2048]
            if vid_emb is None:
                continue
            row = {
                "split": split,
                "video_path": vp,
                "label": label_map[cls],
                "agg": AGGREGATION
            }
            # afegeix e0..e2047
            for j in range(emb_dim):
                row[f"e{j}"] = vid_emb[j]
            rows.append(row)

df = pd.DataFrame(rows)
print("Shape DF:", df.shape)
df.head()

# Guarda CSV (una fila = un vídeo)
df.to_csv(CSV_OUT, index=False)
print(f"CSV guardat a: {CSV_OUT}")


# 5) Entrena Logistic Regression a nivell de VÍDEO
#    (train -> fit, test -> eval)

def split_Xy(df_in):
    feats = [f"e{j}" for j in range(emb_dim)]
    X = df_in[feats].values
    y = df_in["label"].values.astype(int)
    return X, y

df_train = df[df["split"] == "train"].copy()
df_test  = df[df["split"] == "test"].copy()

X_train, y_train = split_Xy(df_train)
X_test,  y_test  = split_Xy(df_test)

# Pipeline: StandardScaler + LogisticRegression
clf = make_pipeline(
    StandardScaler(with_mean=True, with_std=True),
    LogisticRegression(max_iter=5000, solver="lbfgs")
)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
y_scores = clf.predict_proba(X_test)[:, 1] if hasattr(clf[-1], "predict_proba") else y_pred

acc  = accuracy_score(y_test, y_pred)
f1   = f1_score(y_test, y_pred)
try:
    roc = roc_auc_score(y_test, y_scores)
except:
    roc = float("nan")

print("\n=== RESULTATS (VÍDEO) ===")
print("Accuracy:", round(acc, 4))
print("F1-score:", round(f1, 4))
print("ROC-AUC:", round(roc, 4))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=3))